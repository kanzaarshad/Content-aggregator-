# -*- coding: utf-8 -*-
"""Content aggregator

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18U-iNoy4OG3D9RrSO7lzcQeXjhu4dkTE
"""

import requests
from bs4 import BeautifulSoup

class ContentAggregator:
    def __init__(self):
        self.sources = []

    def add_source(self, name, url):
        self.sources.append({'name': name, 'url': url})

    def fetch_content(self):
        aggregated_content = []
        for source in self.sources:
            response = requests.get(source['url'])
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                articles = soup.find_all('article')  # Update this based on the HTML structure of the source
                for article in articles:
                    title = article.find('h2').text.strip()
                    link = article.find('a')['href']
                    content = article.find('p').text.strip()
                    aggregated_content.append({'source': source['name'], 'title': title, 'link': link, 'content': content})
        return aggregated_content

    def display_content(self, content):
        for idx, item in enumerate(content, start=1):
            print(f"{idx}. Source: {item['source']}")
            print(f"   Title: {item['title']}")
            print(f"   Link: {item['link']}")
            print(f"   Content: {item['content']}\n")

# Example usage
aggregator = ContentAggregator()

# Add sources
aggregator.add_source('TechCrunch', 'https://techcrunch.com/')
aggregator.add_source('BBC News', 'https://www.bbc.com/news')

# Fetch and display content
content = aggregator.fetch_content()
aggregator.display_content(content)